"""
IMDb è¯„è®ºçˆ¬è™« - å¢å¼ºç¨³å®šç‰ˆ (Anti-Detect Selenium)
------------------------------------------------
ä¿®æ”¹è¯´æ˜:
1. å…³é—­ Headless æ¨¡å¼ï¼šæµè§ˆå™¨ä¼šå¼¹å‡ºï¼Œæ–¹ä¾¿é€šè¿‡äººå·¥éªŒè¯ã€‚
2. é›†æˆåçˆ¬è™«ä¼ªè£…ï¼šéšè— WebDriver ç‰¹å¾ï¼Œé˜²æ­¢è¢«è¯†åˆ«ä¸ºæœºå™¨äººã€‚
3. å¢åŠ é¡µé¢åŠ è½½è¶…æ—¶è®¾ç½®ï¼šè§£å†³ Read timed out é—®é¢˜ã€‚

ä½¿ç”¨æ–¹æ³•:
    python selenium_scraper.py tt1375666              # çˆ¬å–å•éƒ¨
    python selenium_scraper.py tt1375666 tt0068646   # çˆ¬å–å¤šéƒ¨
"""

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import pandas as pd
import time
import os
import argparse
import random

def scrape_movie(movie_id, target_count=300):
    """çˆ¬å–å•éƒ¨ç”µå½±çš„è¯„è®º"""
    print(f"\n{'='*50}")
    print(f"ğŸ¬ çˆ¬å–ç”µå½±: {movie_id}")
    print(f"ğŸ¯ ç›®æ ‡: {target_count} æ¡è¯„è®º")
    print(f"{'='*50}")

    # --- æµè§ˆå™¨é…ç½® (åçˆ¬è™«æ ¸å¿ƒ) ---
    options = webdriver.ChromeOptions()
    
    # 1. ã€é‡è¦ã€‘å…³é—­æ— å¤´æ¨¡å¼ï¼Œè®©æµè§ˆå™¨æ˜¾ç¤ºå‡ºæ¥
    # è¿™æ ·å¦‚æœé‡åˆ°éªŒè¯ç ï¼Œä½ å¯ä»¥æ‰‹åŠ¨ç‚¹ä¸€ä¸‹ï¼Œç¨‹åºå°±èƒ½ç»§ç»­è·‘
    # options.add_argument('--headless') 
    
    # 2. åŸºç¡€è®¾ç½®
    options.add_argument('--disable-gpu')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--start-maximized') # æœ€å¤§åŒ–çª—å£é˜²æ­¢å…ƒç´ è¢«é®æŒ¡
    
    # 3. åæ£€æµ‹è®¾ç½® (ä¼ªè£…æˆæ­£å¸¸æµè§ˆå™¨)
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)
    options.add_argument('--disable-blink-features=AutomationControlled')
    
    # 4. ä¼ªè£… User-Agent (Mac Chrome)
    options.add_argument('user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    # 5. æ³¨å…¥ JS å½»åº•éšè— WebDriver ç‰¹å¾
    driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
        "source": """
            Object.defineProperty(navigator, 'webdriver', {
            get: () => undefined
            })
        """
    })

    try:
        # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶ (é˜²æ­¢ä¸€ç›´åœ¨è½¬åœˆå¯¼è‡´æŠ¥é”™)
        driver.set_page_load_timeout(60)
        
        url = f"https://www.imdb.com/title/{movie_id}/reviews?sort=submissionDate&dir=desc&ratingFilter=0"
        print(f"ğŸŒ æ­£åœ¨æ‰“å¼€é¡µé¢: {url}")
        
        try:
            driver.get(url)
        except Exception as e:
            print("âš ï¸ é¡µé¢åŠ è½½è¶…æ—¶ï¼Œä½†å¯èƒ½å·²æ˜¾ç¤ºå†…å®¹ï¼Œç»§ç»­å°è¯•...")
            driver.execute_script("window.stop();")
        
        print("ğŸ‘€ é¡µé¢å·²æ‰“å¼€ï¼Œç­‰å¾…æ¸²æŸ“...")
        time.sleep(5) # ç»™è¶³æ—¶é—´è®©é¡µé¢æ˜¾ç¤º

        # å¾ªç¯ç‚¹å‡» "Load More" æŒ‰é’®
        current_count = 0
        click_count = 0
        # è®¡ç®—éœ€è¦ç‚¹å‡»å¤šå°‘æ¬¡ (IMDbä¸€æ¬¡åŠ è½½25æ¡)
        max_clicks = (target_count // 25) + 5
        
        while current_count < target_count and click_count < max_clicks:
            try:
                # å°è¯•å¯»æ‰¾æŒ‰é’®
                load_more_btn = None
                selectors = [
                    "button.ipc-see-more__button",
                    "button[data-testid='see-more-button']",
                    ".load-more-data",
                    "button.ipl-load-more__button",
                    "//button[contains(text(), 'Load More')]"
                ]
                
                for selector in selectors:
                    try:
                        if selector.startswith("//"):
                            load_more_btn = driver.find_element(By.XPATH, selector)
                        else:
                            load_more_btn = driver.find_element(By.CSS_SELECTOR, selector)
                        
                        if load_more_btn and load_more_btn.is_displayed():
                            break
                    except:
                        continue
                
                if not load_more_btn:
                    # å¦‚æœæ‰¾ä¸åˆ°æŒ‰é’®ï¼Œå†æ¬¡æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯æ‰€æœ‰è¯„è®ºäº†
                    reviews_check = driver.find_elements(By.CSS_SELECTOR, "article.user-review-item, div.review-container")
                    if len(reviews_check) >= target_count:
                        print("âœ… å·²è¾¾åˆ°ç›®æ ‡æ•°é‡")
                        break
                    print("âš ï¸ æ‰¾ä¸åˆ°åŠ è½½æ›´å¤šæŒ‰é’®ï¼Œå°è¯•æ»šåŠ¨é¡µé¢...")
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(2)
                    continue
                
                # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
                driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", load_more_btn)
                time.sleep(1) # ç¨å¾®åœé¡¿ï¼Œæ¨¡æ‹Ÿäººç±»
                
                # ç‚¹å‡»æŒ‰é’® (ä½¿ç”¨ JS ç‚¹å‡»æ›´ç¨³å®š)
                driver.execute_script("arguments[0].click();", load_more_btn)
                click_count += 1
                
                # éšæœºç­‰å¾… 2-4 ç§’ (åçˆ¬è™«å…³é”®ï¼šä¸è¦å¤ªæœ‰è§„å¾‹)
                wait_time = random.uniform(2, 4)
                time.sleep(wait_time)
                
                # å®æ—¶æ˜¾ç¤ºè¿›åº¦
                reviews_on_page = driver.find_elements(By.CSS_SELECTOR, "article.user-review-item, div.review-container")
                current_count = len(reviews_on_page)
                print(f"ğŸ“Š å·²åŠ è½½: {current_count} æ¡ (ç‚¹å‡» {click_count} æ¬¡)")
                
            except Exception as e:
                print(f"âš ï¸ ç‚¹å‡»åŠ è½½æ›´å¤šæ—¶å‡ºé”™ (å¯èƒ½æ˜¯å¼¹çª—é˜»æŒ¡ï¼Œè¯·æ‰‹åŠ¨å…³é—­): {e}")
                time.sleep(3) # ç»™ç”¨æˆ·æ—¶é—´æ‰‹åŠ¨å¤„ç†
                continue

        print("ğŸ›‘ åœæ­¢åŠ è½½ï¼Œå¼€å§‹è§£ææ•°æ®...")
        
        # è§£æ HTML
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        # å…¼å®¹ä¸¤ç§ IMDb é¡µé¢ç»“æ„
        review_containers = soup.select('article.user-review-item')
        if not review_containers:
            review_containers = soup.select('div.review-container')
        
        reviews = []
        for container in review_containers:
            review = parse_review(container)
            if review and review.get('content'):
                reviews.append(review)
        
        # æˆªæ–­åˆ°ç›®æ ‡æ•°é‡
        reviews = reviews[:target_count]
        print(f"âœ… æˆåŠŸè§£æ {len(reviews)} æ¡è¯„è®º")
        return reviews

    except Exception as e:
        print(f"âŒ çˆ¬å–ä¸¥é‡å¤±è´¥: {e}")
        return []
    
    finally:
        # ç¨å¾®ç­‰å¾…ä¸€ä¸‹å†å…³é—­ï¼Œä»¥é˜²æœ€åæ—¶åˆ»æŠ¥é”™
        time.sleep(2)
        driver.quit()
        print("ğŸ”Œ æµè§ˆå™¨å·²å…³é—­")


def parse_review(container):
    """è§£æå•æ¡è¯„è®º (ä¿æŒåŸé€»è¾‘)"""
    review = {}
    
    # ç”¨æˆ·å
    user_selectors = ['a[data-testid="author-link"]', 'span.display-name-link a', 'a.author-link']
    for sel in user_selectors:
        tag = container.select_one(sel)
        if tag:
            review['user'] = tag.get_text(strip=True)
            break
    else:
        review['user'] = 'Anonymous'
    
    # æ—¥æœŸ
    date_selectors = ['li.review-date', 'span.review-date', '.date']
    for sel in date_selectors:
        tag = container.select_one(sel)
        if tag:
            review['date'] = tag.get_text(strip=True)
            break
    else:
        review['date'] = ''
    
    # è¯„åˆ†
    rating_selectors = ['span.ipc-rating-star--otherUserAlt', 'span.rating-other-user-rating span', 'span.ipl-rating-star__rating']
    for sel in rating_selectors:
        tag = container.select_one(sel)
        if tag:
            rating_text = tag.get_text(strip=True)
            import re
            match = re.search(r'(\d+)', rating_text)
            if match:
                review['rating'] = f"{match.group(1)}/10"
                break
    else:
        review['rating'] = 'N/A'
    
    # å†…å®¹
    content_selectors = ['div[data-testid="review-overflow"]', 'div.text.show-more__control', 'div.review-text', 'div.content']
    for sel in content_selectors:
        tag = container.select_one(sel)
        if tag:
            review['content'] = tag.get_text(strip=True)
            break
    else:
        review['content'] = ''
    
    return review


def save_reviews(movie_id, reviews, output_dir='data'):
    """ä¿å­˜è¯„è®ºåˆ° CSV"""
    if not reviews:
        print(f"âš ï¸ æ²¡æœ‰è¯„è®ºå¯ä¿å­˜")
        return None
    
    os.makedirs(output_dir, exist_ok=True)
    
    df = pd.DataFrame(reviews)
    filepath = os.path.join(output_dir, f"{movie_id}_reviews.csv")
    # ä½¿ç”¨ utf-8-sig é˜²æ­¢ Excel æ‰“å¼€ä¹±ç 
    df.to_csv(filepath, index=False, encoding='utf-8-sig')
    
    print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {filepath} ({len(reviews)} æ¡)")
    return filepath


def main():
    parser = argparse.ArgumentParser(description='IMDb è¯„è®ºçˆ¬è™« (Selenium å¢å¼ºç‰ˆ)')
    parser.add_argument('movie_ids', nargs='+', help='IMDb ç”µå½± ID (å¦‚ tt1375666)')
    parser.add_argument('--max', type=int, default=300, help='æ¯éƒ¨ç”µå½±æœ€å¤§è¯„è®ºæ•°')
    parser.add_argument('--output', type=str, default='data', help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      IMDb è¯„è®ºçˆ¬è™« - å¢å¼ºç¨³å®šç‰ˆ                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  æç¤º: æµè§ˆå™¨å°†è‡ªåŠ¨æ‰“å¼€ã€‚                        â•‘
â•‘  å¦‚æœçœ‹åˆ° "Verify you are human" æˆ– Cookie å¼¹çª—ï¼Œ  â•‘
â•‘  è¯·åœ¨æµè§ˆå™¨ä¸­ã€æ‰‹åŠ¨ç‚¹å‡»ã€‘é€šè¿‡ï¼Œçˆ¬è™«ä¼šè‡ªåŠ¨ç»§ç»­ï¼      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    results = []
    for i, movie_id in enumerate(args.movie_ids):
        # ç¡®ä¿ ID æ ¼å¼æ­£ç¡®
        if not movie_id.startswith('tt'):
            movie_id = f'tt{movie_id}'
        
        reviews = scrape_movie(movie_id, args.max)
        filepath = save_reviews(movie_id, reviews, args.output)
        
        results.append({
            'movie_id': movie_id,
            'count': len(reviews),
            'filepath': filepath
        })
        
        # å¤šéƒ¨ç”µå½±ä¹‹é—´çš„éšæœºç­‰å¾… (é˜²æ­¢å° IP)
        if i < len(args.movie_ids) - 1:
            wait_time = random.randint(10, 15)
            print(f"â³ ä¸ºäº†å®‰å…¨ï¼Œç­‰å¾… {wait_time} ç§’åç»§ç»­ä¸‹ä¸€éƒ¨...")
            time.sleep(wait_time)
    
    print(f"\nâœ… å…¨éƒ¨å®Œæˆ! æ•°æ®ä¿å­˜åœ¨ {args.output}/ ç›®å½•")


if __name__ == '__main__':
    main()
